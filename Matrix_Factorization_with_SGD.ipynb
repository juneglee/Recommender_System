{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 행렬 요인화 (Matrix Factorization )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추천을 위한 다양한 알고리즘을 분류를 해보면 크게 메모리 기반(memory-based)과 모델 기반(model-based)으로 나눌 수 있다. \n",
    "- 메모리 기반 알고리즘은 추천을 위한 데이터를 모두 메모리에 가지고 있으면서 추천이 필요할 때마다 이 데이터를 사용해서 계산을 해서 추천하는 방식을 말한다. CF가 대표적인 메모리 기반 알고리즘이라고 할 수 있다. \n",
    "- 모델 기반 추천은 데이터로부터 추천을 위한 모델을 구성한 후에 이 모델만 저장하고, 실제 추천을 할 때에는 이 모델을 사용해서 추천하는 방식을 말한다. 행렬 요인화 (Matrix factorization) 방식이 대표적인 모델 기반 추천 알고리즘이다. 또한 딥러닝 방식의 추천도 데이터는 신경망 학습에 사용ㅇ되고 에측은 학습된 신경망을 가지고 한다는 점에서 모델 기반 추천 알고리즘이라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 메모리 기반 추천은 모든 데이터를 메모리에 저장하고 있기 때문에 원래 데이터를 충실하게 사용하는 장점이 있지만 대양의 데이터를 다뤄야 하는 사용 사이트에서는 계산시간이 너무 오래 걸린다는 단점이 있다. \n",
    "- 이에 비해 모델 기반 추언 방식은 원래 데이터는 모형을 만드는 데만 사용하고 일단 모델이 만들어지면 원래 데이터는 사용하지 않기 대문에 대규모 사용 사이트에서는 필요한 빠른 반응이 가능하지만 모델을 만드는 과정에서 많은 계산이 필요하다는 단점이 있다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적으로 메모리 기반 추천은 개별 사용자의 데이터에 집중하는데 비해, 모델 기반 추천은 전체 사용자의 평가 패턴으로부터 모델을 구성하기 때문에 데이터가 가지고 있는 약한 신호(weak signal)도 더 잘 잡아내는 장점이 있다. 여기서 말하는 약한 신호라는 것은 개별 사용자의 행동분석에서는 잘 드러나지 않는 패턴을 말한다. 예를 들어 소수의 사용자가 소수의 영화에 대해서만 특정한 평가 패턴이 있는 경우, 개별 사용자나 개별 아이템에 집중하는 메모리 기반 알고리즘은 이것을 잡아내기 쉽지 않지만 전체 데이터를 대상으로 모델을 구성하는 모델 기반 추천은 이것을 더 잘 잡아 낼 수 있다는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD(Stochastic Gradient Decent)를 사용한 MF 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어떤 도메인에 대해서 사용자와 아이템의 특성을 잘 설명할 수 있는 K개의 요인이 존재하고, 각 사용자와 아이템의 K개 요인에 대한 측정값을 알아 낼 수 있다면 모든 사용자의 모든 아이템에 대한 예측 평점을 계산할 수 있다. 만일 사용자가 어떤 영화에 대해서 실제 평점을 부여하였다면, 그 실제 평점과 예상 평점의 차이가 정확도 이다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating\n",
       "0          196       242       3\n",
       "1          186       302       3\n",
       "2           22       377       1\n",
       "3          244        51       2\n",
       "4          166       346       1\n",
       "...        ...       ...     ...\n",
       "99995      880       476       3\n",
       "99996      716       204       5\n",
       "99997      276      1090       1\n",
       "99998       13       225       2\n",
       "99999       12       203       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('data/u.data', names=r_cols,  sep='\\t',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)            # timestamp 제거\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MF class\n",
    "class MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings) # dataframe 형식으로 전달된 평점을 array로 변경\n",
    "        self.num_users, self.num_items = np.shape(self.R) # 사용자 수와(num_users)와 아이템 수(num_items)를 받아온다 \n",
    "        self.K = K # 잠재요인(latent factor)의 수 \n",
    "        self.alpha = alpha # learning rate\n",
    "        self.beta = beta # 정규화 계수\n",
    "        self.iterations = iterations # 반복횟수\n",
    "        self.verbose = verbose # 중간 학습 과정을 출력\n",
    "    \n",
    "    # Root Mean Squared Error (RMSE) 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero() # R에서 평점이 있는 (0이 아닌) 요소의 인덱스를 가져온다 \n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y) # 사용자 x, 아이템 y에 대해서 평점 예측치 \n",
    "            self.predictions.append(prediction) #\n",
    "            self.errors.append(self.R[x, y] - prediction) # 실제값(R)과 예측값의 차이(errors) 계산해서 오차값 리스트에 추가 \n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "    \n",
    "    # train \n",
    "    def train(self): \n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        # P , Q행렬을 임의 값으로 채움, 평균 0, 표준편차 1/k 인 정규 분포의 난수 발생\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) \n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)) \n",
    "\n",
    "        # Initializing the bias terms\n",
    "        # bias \n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()]) # 전체 평균 b\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero() # 평점 행렬 R 중에서 평점이 있는 (0이 아닌) 요소의 인덱스를 가져온다 \n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)] # SGD를 적용할 대상, 즉 평점이 있는 요소의 인덱스와 평점을 리스트로 만들어 sample에 저장 \n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples) # sample를 임의로 섞는다. \n",
    "            '''\n",
    "            임의로 섞는 이유는 다른 기계학습 알고리즘과 마찬가지로 SGD를 어디서 시작하느냐에 따라 수렴의 속도가 달라질 수 있기 때문에 \n",
    "            매 반복마다 다양한 시작점에서 출발하기 위함이다 \n",
    "            '''\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1, rmse)) \n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f \" % (i+1, rmse))\n",
    "        return training_process\n",
    "    \n",
    "    # Rating prediction for user i and item j\n",
    "    # 평점 에측값을 구하는 함수 \n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j) # 사용자 i, 아이템 j에 대한 평점 예측치를 구한다 \n",
    "            e = (r - prediction) # 실제 평점과 비교해서 오차를 구함\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9585 \n",
      "Iteration: 20 ; Train RMSE = 0.9374 \n",
      "Iteration: 30 ; Train RMSE = 0.9281 \n",
      "Iteration: 40 ; Train RMSE = 0.9226 \n",
      "Iteration: 50 ; Train RMSE = 0.9185 \n",
      "Iteration: 60 ; Train RMSE = 0.9146 \n",
      "Iteration: 70 ; Train RMSE = 0.9101 \n",
      "Iteration: 80 ; Train RMSE = 0.9040 \n",
      "Iteration: 90 ; Train RMSE = 0.8954 \n",
      "Iteration: 100 ; Train RMSE = 0.8843 \n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터 사용 MF\n",
    "# dataframe 형식으로 되어 있는 rating 데이터를 full matrix로 변환한다.\n",
    "# 위에서 설명했듯이 MF 클래스 내부적으로 full matrix(self,R)를 계산하기 때문에 미리 반환\n",
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
    "mf = MF(R_temp, K=30, alpha=0.001, beta=0.02, iterations=100, verbose=True) \n",
    "train_process = mf.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 100번 반복을 한 결과로 매우 좋은 결과를 보임을 알 수 있다. 물론 여기서 train/test set을 나누지 않고, 동일한 데이터를 training, test에 동시에 사용하기 때문에 좋은 결과가 나오는 것이다. 다시 말해서 같은 데이터 training과 예측을 한 결과라고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
