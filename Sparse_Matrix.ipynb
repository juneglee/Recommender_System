{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e319b266",
   "metadata": {},
   "source": [
    "# 대규모 데이터의 처리를 위한 Sparse Matrix\n",
    "- 추천 시스템에서 사용되는 대부분의 데이터는 full matrix로 변환하면 많은 원소가 비어있는(평가하지 않은) 희박행렬(sparse matrix)이다. \n",
    "- 희박행렬이라면 전체 행렬을 저장하는 대신에 행렬의 원소 중에서 실제로 값을 갖는 것만 그 인덱스와 같이 저장해서 사용하는 것이 훨신 효율적일 것이다. sparse matrix의 단점은 데이터를 저장하거나 읽어올 때마다 값이 존재하는지 확인해서 그에 맞는 처리를 해야하기 때문에 소위 말하는 데이터 처리의 overhead cost가 크다는 점이다. 그래서 데이터가 그다지 희박하지 않은 경우에는 sparse matrix를 사용하면 공간 절약의 이점보다 속도 저하의 단점이 오히려 더 크게 된다. 반면에 행렬의 데이터가 희박할수록 sparse matrix을 사용하는 편이 더 낫게 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3754b88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ced4a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "# 20M data 읽어오기\n",
    "ratings = pd.read_csv('data/ratings-20m.csv', names=r_cols,  sep=',',encoding='latin-1')\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2fb770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test 분리\n",
    "from sklearn.utils import shuffle\n",
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state=1)\n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78766ea1",
   "metadata": {},
   "source": [
    "### Sparse matrix 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4230650",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(ratings['rating'])\n",
    "row_indices = np.array(ratings['user_id'])\n",
    "col_indices = np.array(ratings['movie_id'])\n",
    "ratings = csr_matrix((data, (row_indices, col_indices)), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8864219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New MF class for training & testing\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = ratings\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "    # train set의 RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    # Ratings for user i and item j\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Stochastic gradient descent to get optimized P and Q matrix\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "\n",
    "    # Test set을 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):              # test 데이터에 있는 각 데이터에 대해서\n",
    "            x, y, z = ratings_test.iloc[i]              # user_id, item_id, rating 가져오기\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0                            # Setting test set ratings to 0\n",
    "        self.test_set = test_set\n",
    "        return test_set                                 # Return test set\n",
    "\n",
    "    # Test set의 RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    # Training 하면서 test set의 정확도를 계산\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # Initializing the bias terms\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    # Ratings for given user_id and item_id\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(user_id, item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42360d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing MF RMSE\n",
    "R_temp = ratings.copy()\n",
    "mf = NEW_MF(R_temp, K=200, alpha=0.001, beta=0.02, iterations=190, verbose=True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73465dc1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
